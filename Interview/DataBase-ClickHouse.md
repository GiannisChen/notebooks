## 数据库 ClickHouse 面试

- ClickHouse：https://clickhouse.com/

- 博客：
  - https://www.cnblogs.com/huanghanyu/p/16644873.html
  - https://blog.51cto.com/u_9928699/3430822



#### 1. ClickHouse的特点

**优点**：

- 支持标准SQL，但不具备存储过程和一些常见语法糖；
- 列式存储，更快的过滤操作以及更好的数据压缩，支持默认（LZ4）和指定压缩算法（Gorilla，ZSTD等）；
- 向量化执行引擎；
- 逻辑上的关系型模型；
- 丰富的表引擎；
- 更好的并行处理；
- 在线查询；
- 数据分片；

**缺点**：

- 不支持事务；
- 不擅长按行粒度查询，不擅长按行对数据进行删改（影响压缩、持久化等）



#### 2. ClickHouse的表引擎

- **MergeTree系列**：

  - MergeTree：存储有序的数据，数据存储分块，支持数据备份，支持数据采样；
  - ReplacingMergeTree：在MergeTree的基础上，去除重复的key的数据；
  - Summing MergeTree：在MergeTree的基础上，重复的key的数据将会累加到一行中，如果可以进行累加的话；
  - AggregatingMergeTree：在MergeTree的基础上，重复key的数据将会以约定的聚合函数进行聚合，详细见：https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/aggregatingmergetree#example-of-an-aggregated-materialized-view；
  - CollapsingMergeTree：在MergeTree的基础上，增加了版本控制，用一个sign列标识，`1` 标识当前状态 `-1` 标识失效状态，`select` 时失效状态将被隐藏；
  - VersionedCollapsingMergeTree：在MergeTree的基础上，增加了版本控制，用连续的 `Version` 列进行版本控制；

- **Log系列**：

  Log系列表引擎功能相对简单，主要用于快速写入小表（一百万行左右的表），然后全部读出的场景。即一次写入多次查询。数据存储在磁盘上，当数据写入时将会以追加的方式写入到文件的末尾。

  Log系列

  1. 不支持并发读写，当向表中写入数据时，针对这张表的查询会被阻塞，直至写入动作结束；
  2. 不支持索引；
  3. 不支持原子写：如果某些操作（异常的服务器关闭）中断了写操作，则可能会获得带有损坏数据的表
  4. 不支持ALTER操作（这些操作会修改表设置或数据，比如delete、update等等）

- **外部集成表引擎系列**：

  - ODBC：通过指定odbc连接读取数据源；
  - JDBC：通过指定jdbc连接读取数据源；
  - MySQL：将MySQL作为数据存储，直接查询其数据；
  - HDFS：直接读取HDFS上的特定格式的数据文件；
  - Kafka：将Kafka数据导入ClickHouse；
  - RabbitMQ：与Kafka类似；



#### 3. ClickHouse性能优异原因概述

1. 将硬件性能发挥到极致，基于将硬件功效最大化的目的，ClickHouse会在内存中进行 `GROUP BY` ，并且使用HashTable装载数据。
2. 算法方面精益求精，在ClickHouse的底层实现中，经常会面对一些重复的场景，例如字符串子串查询、数组排序、使用HashTable等，对于不同的场景会用不同的算法。除了字符串之外，其余的场景也与它类似，ClickHouse会使用最合适、最快的算法。如果世面上出现了号称性能强大的新算法，ClickHouse团队会立即将其纳入并进行验证。如果效果不错，就保留使用；如果性能不尽人意，就将其抛弃。
3. 特定场景，特殊优化，针对同一个场景的不同状况，选择使用不同的实现方式，尽可能将性能最大化。关于这一点，其实在前面介绍字符串查询时，针对不同场景选择不同算法的思路就有体现了。类似的例子还有很多，例如去重计数 `uniqCombined` 函数，会根据数据量的不同选择不同的算法：当数据量较小的时候，会选择Array保存；当数据量中等的时候，会选择HashSet；而当数据量很大的时候，则使用HyperLogLog算法。
   对于数据结构比较清晰的场景，会通过代码生成技术实现循环展开，以减少循环次数。接着就是大家熟知的大杀器——**向量化执行**了。SIMD被广泛地应用于文本转换、数据过滤、数据解压和JSON转换等场景。相较于单纯地使用CPU，利用寄存器暴力优化也算是一种降维打击了。
4. 持续测试，持续改进，如果只是单纯地在上述细节上下功夫，还不足以构建出如此强大的ClickHouse，还需要拥有一个能够持续验证、持续改进的机制。由于Yandex的天然优势，ClickHouse经常会使用真实的数据进行测试，这一点很好地保证了测试场景的真实性。与此同时，ClickHouse也是我见过的发版速度最快的开源软件了，差不多每个月都能发布一个版本。没有一个可靠的持续集成环境，这一点是做不到的。正因为拥有这样的发版频率，ClickHouse才能够快速迭代、快速改进。
5. 行存储和列存储，分析场景中，我们一般会读大量的行而取少量的列，在列式存储结构下，我们只需要取对应的列数据就可以，不参与计算的列完全不会被扫描到，这会极大的降低磁盘 IO 的消耗。
6. 数据压缩，基于列式存储的结构，同一列中的数据属于同一类型，压缩效果会更加显著。列存储往有着高达十倍甚至更高的压缩比，节省了大量的存储空间，降低了存储成本。
7. 向量化执行引擎，SIMD（Single Instruction Multiple Data）即单条指令操作多条数据，它是通过数据并行以提高性能的一种方式，可以简单理解为在寄存器层面对程序中的数据做并行处理，ClickHouse 在能够提升计算效率的地方大量使用了 SIMD，通过使用 SIMD，基本上能带来几倍的性能提升，像阿里云的 PolarDB-X 也引入了向量化执行引擎，为表达式计算带来了几十倍的性能提升。
8. 多线程与分布式，分布式领域存在一条定律，计算移动比数据移动更加划算，这也是其核心所在，将数据的计算直接发放到数据所在的服务器，多机并行处理，再把最终的结果汇集在一起；另外 ClickHouse 也通过线程级别并行的方式为效率进一步提速，极致去利用服务器的资源。
9. 更多的用户决定，将更多的选择权交给用户，用户根据使用场景决定使用的表引擎、排序键（sorting key）、分段（partition key）等。



#### 4. ClickHouse常见问题

1. 重启 ClickHouse 服务的时间会比较长：主要是由于该节点数据分片过多导致加载缓慢。

2. 数据插入报错 too many parts exception：主要是由于数据插入过于频繁，导致数据分片在后台 merge 缓慢，ClickHouse 启动自我保护机制，拒绝数据继续插入。此时可尝试增大插入数据的 batch_size （10 万）并降低数据插入的频率（每秒 1 次）以缓解该问题。

3. **复制表变为只读**：

   1. 由于 ClickHouse 无法连接 ZooKeeper 集群或 ZooKeeper 上该复制表的元数据丢失导致的，此时新数据无法插入该表。若要解决该问题，首先要检查 ZooKeeper 的连接状况，如果连接失败，则需进一步检查网络状态以及 ZooKeeper 的状态，连接恢复后，复制表就可以继续插入数据了。如果连接正常而元数据丢失，此时可以将复制表转为非复制表然后再进行数据插入操作。
   2. 由于插入数据过多，ZooKeeper申请了过多的存储空间导致数据无法正确写入，CK数据表上锁变为只读模式。

4. 执行 JOIN 操作时内存超限：可能是由于 JOIN 前后的两个子查询中没有添加明确的过滤条件导致的，也有可能是由于 JOIN 的数据本身就很大，无法全部加载到内存。此时可以尝试增加过滤条件以减小数据量，或者适当修改配置文件中的内存限制，以装载更多的数据。

5. **数据直接写入的风险**：

   用户写入 ClickHouse 一般有两种选择：分布式表（i.e. Distributed），MergeTree 表：

   - **写入分布式表**：

     数据写入分布式表时，它会将数据先放入本地磁盘的缓冲区，再异步分发给所有节点上的 MergeTree 表。如果数据在同步给 MergeTree 里面之前这个节点宕机了，数据就可能会丢失；此时如果在失败后再重试，数据就可能会写重。因而，直接将数据写入用分布式表时，不太好保证数据准确性的和一致性。

     当然这个分布式表还有其他问题，一般来说一个 ClickHouse 集群会配置多个 shard，每个 shard 都会建立 MergeTree 表和对应的分布式表。如果直接把数据写入分布式表，数据就可能会分发给每个 shard。假设有 N 个节点，每个节点每秒收到一个 INSERT Query，分发 N 次之后，一共就是每秒生成 NxN 个 part 目录。集群 shard 数越多，分发产生的小文件也会越多，最后会导致你写入到 MergeTree 的 Part 的数会特别多，最后会拖垮整个文件的系统。


   - **写入 MergeTree 表**：

     直接写入 MergeTree 表可以解决数据分发的问题，但是依然抗不住高频写入，如果业务方写入频次控制不好，仍然有可能导致 ClickHouse 后台合并的速度跟不上写入的速度，最后会使得文件系统压力过大。



#### 5. ClickHouse的问题排查方法

1. 检查 ClickHouse 运行状态，确保服务正常运行。
2. 检查 ClickHouse 错误日志文件，寻找问题根源。
3. 检查系统日志文件 （/var/log/messages） 中与 ClickHouse 相关的记录，查看是否是系统操作导致 ClickHouse 异常。
4. 对于未知问题或 BUG，可以到官方 GitHub 仓库的 issue 下寻求帮助，需提供完整的问题描述和错误日志信息。

---



## 数据库 ClickHouse 源码

- ClickHouse官方架构概述：https://clickhouse.com/docs/en/development/architecture/（中文版：https://clickhouse.com/docs/zh/development/architecture/）

- 博客：https://zhuanlan.zhihu.com/p/453705083



