## FastHTTP æºç é˜…è¯»

- Githubåœ°å€ï¼šhttps://github.com/valyala/fasthttp



### å‰è¨€

`fasthttp` æ˜¯ä¸€ä¸ªåœ¨å¾ˆå¤šåœºæ™¯ä¸­éƒ½å‡ºç°è¿‡çš„é¡¹ç›®ï¼Œé¦–å…ˆå‡ºåœºäº **valyala** çš„æ—¶åºæ•°æ®åº“ç³»ç»Ÿ [VictoriaMetrics](https://github.com/VictoriaMetrics/VictoriaMetrics) ä¸­ï¼Œä½œä¸ºé«˜æ€§èƒ½æ•°æ®åº“çš„æ¥å£ä½¿ç”¨ï¼›åæ¥ï¼Œåœ¨å¼‚å†›çªèµ·çš„åç«¯æ¶æ„ [fiber](https://github.com/gofiber/fiber) ä¸­ï¼Œä¹Ÿå‘ç°äº† `fasthttp` çš„èº«å½±ï¼›åŒæ—¶ï¼Œåœ¨å‰æ®µæ—¶é—´çœ‹åç¨‹æ± çš„æ—¶å€™ï¼Œç¬¬ä¸‰æ¬¡çœ‹åˆ°äº† `fasthttp` ï¼Œä½œä¸ºè¾ƒç«çš„ [ants](https://github.com/panjf2000/ants) çš„æ€è·¯æ¥æºè€Œè¢«æåŠã€‚

`fasthttp` å’Œ `VictoriaMetrics` ä¸­ä¸€è„‰ç›¸æ‰¿äº†æ± åŒ–æ“ä½œï¼Œæ± åŒ–è®©èµ„æºåˆ©ç”¨å˜å¾—æ›´åŠ åˆç†ï¼ŒåŒæ—¶ä¹Ÿèƒ½é¿å…è¿‡å¤šçš„ GC çš„ä»‹å…¥ã€‚ä½œä¸ºå·ç§°æ¯”åŸç”Ÿ `net/http` å¿«ä¸Šæ•°å€ä¹ƒè‡³æ•°åå€çš„åŒ…ï¼ˆå½“ç„¶ï¼Œä½œè€…ä¹Ÿå¼ºè°ƒäº†åœ¨ä¸€å®šçš„ä½¿ç”¨åœºæ™¯ä¸‹ï¼ŒåŒ…æ‹¬é«˜è´Ÿè½½ç­‰ï¼‰ï¼Œè‡ªç„¶éœ€è¦ä¸€æ¢ç©¶ç«Ÿã€‚ä½œä¸ºç¬”è€…å†™ä¸‹çš„ç¬¬ä¸€ç¯‡åŸåˆ›æºç è§£è¯»ï¼Œå¿…ç„¶å­˜åœ¨ä¸è¶³ä¹‹å¤„ä¹ƒè‡³è°¬è¯¯ï¼Œå¦‚æœ‰æœºä¼šå®šå½“è¿”å·¥è®¢æ­£ã€‚



### åˆè§

æ ‡å‡†åº“ `net/http` é€šè¿‡å‡½æ•° `http.ListenAndServe` æä¾›æœåŠ¡ï¼Œ`fasthttp` åˆ™æä¾›äº†é•¿å¾—å¾ˆåƒçš„å‡½æ•° `fasthttp.ListenAndServe` ä½œä¸ºæ›¿ä»£ã€‚æˆ‘ä»¬ä»¥è¯¥å‡½æ•°ä¸ºåˆ‡å…¥ï¼š

```go
package main

import (
	"fmt"
	"github.com/valyala/fasthttp"
)

func fastHTTPHandler(ctx *fasthttp.RequestCtx) {
	fmt.Fprintf(ctx, "Hi there! RequestURI is %q", ctx.RequestURI())
}

func main() {
	fasthttp.ListenAndServe(":8080", fastHTTPHandler)
}
```

è¿è¡Œä¸€ä¸‹ï¼š

![fasthttp-running-result](Images/fasthttp-running-result.png)

æ˜¯ä¸€ä¸ªç®€å•çš„ç»“æœï¼Œé‚£ä¹ˆå…¶ä¸­æœ‰å•¥ç„å¦™å‘¢ï¼Ÿ

```go
// ListenAndServe serves HTTP requests from the given TCP addr
// using the given handler.
func ListenAndServe(addr string, handler RequestHandler) error {
	s := &Server{
		Handler: handler,
	}
	return s.ListenAndServe(addr)
}
```

é¦–å…ˆä¼šç”Ÿæˆä¸€ä¸ªé»˜è®¤çš„ `Server` ï¼Œç”¨æ¥æ‰¿è½½æ•´ä¸ªæœåŠ¡å™¨çš„ä¿¡æ¯ï¼Œ`Server` éƒ¨åˆ†é•¿è¿™æ ·ï¼š

```go
// Server implements HTTP server.
//
// Default Server settings should satisfy the majority of Server users.
// Adjust Server settings only if you really understand the consequences.
//
// It is forbidden copying Server instances. Create new Server instances
// instead.
//
// It is safe to call Server methods from concurrently running goroutines.
type Server struct {
	noCopy noCopy //nolint:unused,structcheck

	// Handler for processing incoming requests.
	//
	// Take into account that no `panic` recovery is done by `fasthttp` (thus any `panic` will take down the entire server).
	// Instead the user should use `recover` to handle these situations.
	Handler RequestHandler

	// ErrorHandler for returning a response in case of an error while receiving or parsing the request.
	//
	// The following is a non-exhaustive list of errors that can be expected as argument:
	//   * io.EOF
	//   * io.ErrUnexpectedEOF
	//   * ErrGetOnly
	//   * ErrSmallBuffer
	//   * ErrBodyTooLarge
	//   * ErrBrokenChunks
	ErrorHandler func(ctx *RequestCtx, err error)

	// HeaderReceived is called after receiving the header
	//
	// non zero RequestConfig field values will overwrite the default configs
	HeaderReceived func(header *RequestHeader) RequestConfig

	// ContinueHandler is called after receiving the Expect 100 Continue Header
	//
	// https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html#sec8.2.3
	// https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.1.1
	// Using ContinueHandler a server can make decisioning on whether or not
	// to read a potentially large request body based on the headers
	//
	// The default is to automatically read request bodies of Expect 100 Continue requests
	// like they are normal requests
	ContinueHandler func(header *RequestHeader) bool

	// Server name for sending in response headers.
	//
	// Default server name is used if left blank.
	Name string

	// The maximum number of concurrent connections the server may serve.
	//
	// DefaultConcurrency is used if not set.
	//
	// Concurrency only works if you either call Serve once, or only ServeConn multiple times.
	// It works with ListenAndServe as well.
	Concurrency int

	// Per-connection buffer size for requests' reading.
	// This also limits the maximum header size.
	//
	// Increase this buffer if your clients send multi-KB RequestURIs
	// and/or multi-KB headers (for example, BIG cookies).
	//
	// Default buffer size is used if not set.
	ReadBufferSize int

	// Per-connection buffer size for responses' writing.
	//
	// Default buffer size is used if not set.
	WriteBufferSize int

	// ReadTimeout is the amount of time allowed to read
	// the full request including body. The connection's read
	// deadline is reset when the connection opens, or for
	// keep-alive connections after the first byte has been read.
	//
	// By default request read timeout is unlimited.
	ReadTimeout time.Duration

	// WriteTimeout is the maximum duration before timing out
	// writes of the response. It is reset after the request handler
	// has returned.
	//
	// By default response write timeout is unlimited.
	WriteTimeout time.Duration

	// IdleTimeout is the maximum amount of time to wait for the
	// next request when keep-alive is enabled. If IdleTimeout
	// is zero, the value of ReadTimeout is used.
	IdleTimeout time.Duration

	// Maximum number of concurrent client connections allowed per IP.
	//
	// By default unlimited number of concurrent connections
	// may be established to the server from a single IP address.
	MaxConnsPerIP int

	// Maximum number of requests served per connection.
	//
	// The server closes connection after the last request.
	// 'Connection: close' header is added to the last response.
	//
	// By default unlimited number of requests may be served per connection.
	MaxRequestsPerConn int

	// MaxKeepaliveDuration is a no-op and only left here for backwards compatibility.
	// Deprecated: Use IdleTimeout instead.
	MaxKeepaliveDuration time.Duration

	// MaxIdleWorkerDuration is the maximum idle time of a single worker in the underlying
	// worker pool of the Server. Idle workers beyond this time will be cleared.
	MaxIdleWorkerDuration time.Duration

	// Period between tcp keep-alive messages.
	//
	// TCP keep-alive period is determined by operation system by default.
	TCPKeepalivePeriod time.Duration

	// Maximum request body size.
	//
	// The server rejects requests with bodies exceeding this limit.
	//
	// Request body size is limited by DefaultMaxRequestBodySize by default.
	MaxRequestBodySize int

	// Whether to disable keep-alive connections.
	//
	// The server will close all the incoming connections after sending
	// the first response to client if this option is set to true.
	//
	// By default keep-alive connections are enabled.
	DisableKeepalive bool

	// Whether to enable tcp keep-alive connections.
	//
	// Whether the operating system should send tcp keep-alive messages on the tcp connection.
	//
	// By default tcp keep-alive connections are disabled.
	TCPKeepalive bool

	// Aggressively reduces memory usage at the cost of higher CPU usage
	// if set to true.
	//
	// Try enabling this option only if the server consumes too much memory
	// serving mostly idle keep-alive connections. This may reduce memory
	// usage by more than 50%.
	//
	// Aggressive memory usage reduction is disabled by default.
	ReduceMemoryUsage bool

	// Rejects all non-GET requests if set to true.
	//
	// This option is useful as anti-DoS protection for servers
	// accepting only GET requests and HEAD requests. The request size is limited
	// by ReadBufferSize if GetOnly is set.
	//
	// Server accepts all the requests by default.
	GetOnly bool

	// Will not pre parse Multipart Form data if set to true.
	//
	// This option is useful for servers that desire to treat
	// multipart form data as a binary blob, or choose when to parse the data.
	//
	// Server pre parses multipart form data by default.
	DisablePreParseMultipartForm bool

	// Logs all errors, including the most frequent
	// 'connection reset by peer', 'broken pipe' and 'connection timeout'
	// errors. Such errors are common in production serving real-world
	// clients.
	//
	// By default the most frequent errors such as
	// 'connection reset by peer', 'broken pipe' and 'connection timeout'
	// are suppressed in order to limit output log traffic.
	LogAllErrors bool

	// Will not log potentially sensitive content in error logs
	//
	// This option is useful for servers that handle sensitive data
	// in the request/response.
	//
	// Server logs all full errors by default.
	SecureErrorLogMessage bool

	// Header names are passed as-is without normalization
	// if this option is set.
	//
	// Disabled header names' normalization may be useful only for proxying
	// incoming requests to other servers expecting case-sensitive
	// header names. See https://github.com/valyala/fasthttp/issues/57
	// for details.
	//
	// By default request and response header names are normalized, i.e.
	// The first letter and the first letters following dashes
	// are uppercased, while all the other letters are lowercased.
	// Examples:
	//
	//     * HOST -> Host
	//     * content-type -> Content-Type
	//     * cONTENT-lenGTH -> Content-Length
	DisableHeaderNamesNormalizing bool

	// SleepWhenConcurrencyLimitsExceeded is a duration to be slept of if
	// the concurrency limit in exceeded (default [when is 0]: don't sleep
	// and accept new connections immediately).
	SleepWhenConcurrencyLimitsExceeded time.Duration

	// NoDefaultServerHeader, when set to true, causes the default Server header
	// to be excluded from the Response.
	//
	// The default Server header value is the value of the Name field or an
	// internal default value in its absence. With this option set to true,
	// the only time a Server header will be sent is if a non-zero length
	// value is explicitly provided during a request.
	NoDefaultServerHeader bool

	// NoDefaultDate, when set to true, causes the default Date
	// header to be excluded from the Response.
	//
	// The default Date header value is the current date value. When
	// set to true, the Date will not be present.
	NoDefaultDate bool

	// NoDefaultContentType, when set to true, causes the default Content-Type
	// header to be excluded from the Response.
	//
	// The default Content-Type header value is the internal default value. When
	// set to true, the Content-Type will not be present.
	NoDefaultContentType bool

	// KeepHijackedConns is an opt-in disable of connection
	// close by fasthttp after connections' HijackHandler returns.
	// This allows to save goroutines, e.g. when fasthttp used to upgrade
	// http connections to WS and connection goes to another handler,
	// which will close it when needed.
	KeepHijackedConns bool

	// CloseOnShutdown when true adds a `Connection: close` header when when the server is shutting down.
	CloseOnShutdown bool

	// StreamRequestBody enables request body streaming,
	// and calls the handler sooner when given body is
	// larger then the current limit.
	StreamRequestBody bool

	// ConnState specifies an optional callback function that is
	// called when a client connection changes state. See the
	// ConnState type and associated constants for details.
	ConnState func(net.Conn, ConnState)

	// Logger, which is used by RequestCtx.Logger().
	//
	// By default standard logger from log package is used.
	Logger Logger

	// TLSConfig optionally provides a TLS configuration for use
	// by ServeTLS, ServeTLSEmbed, ListenAndServeTLS, ListenAndServeTLSEmbed,
	// AppendCert, AppendCertEmbed and NextProto.
	//
	// Note that this value is cloned by ServeTLS, ServeTLSEmbed, ListenAndServeTLS
	// and ListenAndServeTLSEmbed, so it's not possible to modify the configuration
	// with methods like tls.Config.SetSessionTicketKeys.
	// To use SetSessionTicketKeys, use Server.Serve with a TLS Listener
	// instead.
	TLSConfig *tls.Config

	// FormValueFunc, which is used by RequestCtx.FormValue and support for customising
	// the behaviour of the RequestCtx.FormValue function.
	//
	// NetHttpFormValueFunc gives a FormValueFunc func implementation that is consistent with net/http.
	FormValueFunc FormValueFunc

	nextProtos map[string]ServeHandler

	concurrency      uint32
	concurrencyCh    chan struct{}
	perIPConnCounter perIPConnCounter

	ctxPool        sync.Pool
	readerPool     sync.Pool
	writerPool     sync.Pool
	hijackConnPool sync.Pool

	// We need to know our listeners and idle connections so we can close them in Shutdown().
	ln []net.Listener

	idleConns   map[net.Conn]time.Time
	idleConnsMu sync.Mutex

	mu   sync.Mutex
	open int32
	stop int32
	done chan struct{}
}
```

`Server` ä¸­çš„å±æ€§å¤§è‡´å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š

- **æœåŠ¡å™¨é…ç½®**

  ```go
  type Server struct {
      Name string
      Concurrency int
      ...
      StreamRequestBody bool
  }
  ```

  ä¸å¦‚ä½•ä½¿ç”¨è¯¥æœåŠ¡å™¨æœ‰å…³ï¼Œå¹¶ä¸æ˜¯è¿™é‡Œçš„é‡ç‚¹ã€‚

- **æ—¥å¿—**

  ```go
  type Server struct {
      Logger Logger
  }
  ```

  æ—¥å¿—ï¼Œåœ¨æœ¬ç‰‡æ–‡ç« ä¸­æ›´åŠ ä¸é‡è¦äº†ğŸ˜€

- **æ± åŒ–**

  ```go
  type Server struct {
      ctxPool        sync.Pool
  	readerPool     sync.Pool
  	writerPool     sync.Pool
  	hijackConnPool sync.Pool
      ...
  }
  ```

  é‡è¦éƒ¨åˆ†ï¼Œæ˜¯èŠ‚çº¦å†…å­˜å¼€æ”¯çš„é‡è¦æ¸ é“ï¼Œä¸€èˆ¬ç”¨ `sync.Pool` ã€‚

- **åŒæ­¥æ§åˆ¶**

  ```go
  type Server struct {
      open int32
  	stop int32
  	done chan struct{}
      ...
  }
  ```

  åŒæ­¥æ§åˆ¶ç”¨çš„ï¼Œé˜²æ­¢åç¨‹ä¹‹é—´æ— åºè¿è¡Œã€‚



### æ± åŒ–éƒ¨åˆ†

è®©æˆ‘ä»¬å›åˆ°**è°ƒç”¨æ ˆ**ä¸Šï¼š

```go
// ListenAndServe serves HTTP requests from the given TCP4 addr.
// Pass custom listener to Serve if you need listening on non-TCP4 media
// such as IPv6.
// Accepted connections are configured to enable TCP keep-alives.
func (s *Server) ListenAndServe(addr string) error {
	ln, err := net.Listen("tcp4", addr)
	if err != nil {
		return err
	}
	return s.Serve(ln)
}

// Serve serves incoming connections from the given listener.
// Serve blocks until the given listener returns permanent error.
func (s *Server) Serve(ln net.Listener) error {
	...
	s.mu.Lock()
	{
		// s.doneå’Œs.concurrencyChçš„åˆå§‹åŒ–
	}
	s.mu.Unlock()

	wp := &workerPool{
		WorkerFunc:            s.serveConn,
		MaxWorkersCount:       maxWorkersCount,
		LogAllErrors:          s.LogAllErrors,
		MaxIdleWorkerDuration: s.MaxIdleWorkerDuration,
		Logger:                s.logger(),
		connState:             s.setState,
	}
	wp.Start()
	...
}
```

é¦–å…ˆæ¥çœ‹ä¸ŠåŠéƒ¨åˆ†ï¼Œå¼€å¯ä¸€ä¸ªæ–°å·¥ä½œæ±  `workerPool` ï¼š

```go
// workerPool serves incoming connections via a pool of workers
// in FILO order, i.e. the most recently stopped worker will serve the next
// incoming connection.
// Such a scheme keeps CPU caches hot (in theory).
type workerPool struct {
	// Function for serving server connections.
	// It must leave c unclosed.
	WorkerFunc ServeHandler
	MaxWorkersCount int
	LogAllErrors bool
	MaxIdleWorkerDuration time.Duration
	Logger Logger

	lock         sync.Mutex
	workersCount int
	mustStop     bool

	ready []*workerChan
	stopCh chan struct{}
	workerChanPool sync.Pool
	connState func(net.Conn, ConnState)
}

type workerChan struct {
	lastUseTime time.Time
	ch          chan net.Conn
}
```



#### workerPool.Start() 

```go
func (wp *workerPool) Start() {
	if wp.stopCh != nil {
		panic("BUG: workerPool already started")
	}
	wp.stopCh = make(chan struct{})
	stopCh := wp.stopCh
	wp.workerChanPool.New = func() interface{} {
		return &workerChan{
			ch: make(chan net.Conn, workerChanCap),
		}
	}
	go func() {
		var scratch []*workerChan
		for {
			wp.clean(&scratch)
			select {
			case <-stopCh:
				return
			default:
				time.Sleep(wp.getMaxIdleWorkerDuration())
			}
		}
	}()
}
```

ä¸€äº›ç®€å•çš„åˆå§‹åŒ–ï¼Œä¸»è¦æ˜¯ `wp.workerChanPool.New` è®¾å®šåˆå§‹åŒ–å‡½æ•°ã€‚å¼€å¯ä¸€ä¸ªåç¨‹ï¼ˆç±»ä¼¼äºå®ˆæŠ¤åç¨‹æˆ–è€… GC åç¨‹ï¼‰ï¼Œç”¨äºç›‘æ§â€œè¿‡æœŸâ€çš„ `workers` ï¼Œæ¯æ¬¡éƒ½ä¼šä¼‘çœ  `maxIdleWorkerDuration` çš„æ—¶é—´ã€‚ç›´åˆ°æœ‰å…³é—­æ•´ä¸ª `workerPool` çš„é€šçŸ¥ï¼ˆç»å…¸ `stopCh` ï¼‰å‘é€äº†å…³é—­æ¶ˆæ¯ã€‚



#### workerPool.Stop()

```go
func (wp *workerPool) Stop() {
	if wp.stopCh == nil {
		panic("BUG: workerPool wasn't started")
	}
	close(wp.stopCh)
	wp.stopCh = nil

	// Stop all the workers waiting for incoming connections.
	// Do not wait for busy workers - they will stop after
	// serving the connection and noticing wp.mustStop = true.
	wp.lock.Lock()
	ready := wp.ready
	for i := range ready {
		ready[i].ch <- nil
		ready[i] = nil
	}
	wp.ready = ready[:0]
	wp.mustStop = true
	wp.lock.Unlock()
}
```

å¯¹æ‰€æœ‰å‡†å¤‡å°±ç»ªçš„ `workerChan` é€ä¸€æ¸…é™¤ï¼Œå½“ç„¶ï¼Œè¿è¡Œä¸­çš„ `workers` å¹¶ä¸ä¼šå› æ­¤å—åˆ°å½±å“ï¼Œä»–ä»¬çš„å…³é—­æ˜¯åœ¨è¯»åˆ° `wp.mustStop` ä¸º `true` çš„æ—¶å€™è‡ªå·±å…³é—­ã€‚



#### workerPool.clean()

```go
func (wp *workerPool) clean(scratch *[]*workerChan) {
	maxIdleWorkerDuration := wp.getMaxIdleWorkerDuration()

	// Clean least recently used workers if they didn't serve connections
	// for more than maxIdleWorkerDuration.
	criticalTime := time.Now().Add(-maxIdleWorkerDuration)

	wp.lock.Lock()
	ready := wp.ready
	n := len(ready)

	// Use binary-search algorithm to find out the index of the least recently worker which can be cleaned up.
	l, r, mid := 0, n-1, 0
	for l <= r {
		mid = (l + r) / 2
		if criticalTime.After(wp.ready[mid].lastUseTime) {
			l = mid + 1
		} else {
			r = mid - 1
		}
	}
	i := r
	if i == -1 {
		wp.lock.Unlock()
		return
	}

	*scratch = append((*scratch)[:0], ready[:i+1]...)
	m := copy(ready, ready[i+1:])
	for i = m; i < n; i++ {
		ready[i] = nil
	}
	wp.ready = ready[:m]
	wp.lock.Unlock()

	// Notify obsolete workers to stop.
	// This notification must be outside the wp.lock, since ch.ch
	// may be blocking and may consume a lot of time if many workers
	// are located on non-local CPUs.
	tmp := *scratch
	for i := range tmp {
		tmp[i].ch <- nil
		tmp[i] = nil
	}
}
```

- é¦–å…ˆä¸ŠåŠéƒ¨åˆ†æ˜¯é€šè¿‡ä¸€ä¸ª**äºŒåˆ†ç®—æ³•**æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ€å°‘æœ€è¿‘ä½¿ç”¨ï¼ˆLeast Recentlyï¼‰çš„è¿æ¥ï¼Œæ¢å¥è¯è¯´ï¼Œå°±æ˜¯ä¸Šæ¬¡ä½¿ç”¨æ—¶é—´æ¯”è¾ƒé å‰çš„é‚£äº›ï¼Œåˆ’åˆ†æ ‡å‡†å°±æ˜¯æ¯” `criticalTime` è¦æ—©ï¼Œå‰©ä½™çš„å°±æ‰”åˆ° `scratch` é‡Œé¢ã€‚
- ä¸‹åŠéƒ¨åˆ†å°±æ¶‰åŠ `scratch` é‡Œçš„å…ƒç´ ä¸€ä¸€é€šçŸ¥éœ€è¦å…³é—­äº†ï¼Œè¿™ä¸ªæ“ä½œåœ¨ `Stop()` ä¸­å·²ç»è§è¿‡äº†ã€‚



#### workerPool.getCh()

```go
func (wp *workerPool) getCh() *workerChan {
	var ch *workerChan
	createWorker := false

	wp.lock.Lock()
	ready := wp.ready
	n := len(ready) - 1
	if n < 0 {
		if wp.workersCount < wp.MaxWorkersCount {
			createWorker = true
			wp.workersCount++
		}
	} else {
		ch = ready[n]
		ready[n] = nil
		wp.ready = ready[:n]
	}
	wp.lock.Unlock()

	if ch == nil {
		if !createWorker {
			return nil
		}
		vch := wp.workerChanPool.Get()
		ch = vch.(*workerChan)
		go func() {
			wp.workerFunc(ch)
			wp.workerChanPool.Put(vch)
		}()
	}
	return ch
}
```

è¿™æ˜¯æˆ‘è®¤ä¸ºæ¯”è¾ƒé‡è¦çš„å‡½æ•°ä¹‹ä¸€ï¼Œ`getCh` ä¼šè¿”å›ä¸€ä¸ª `workerChan` çš„å¼•ç”¨ï¼Œä½†æ˜¯æˆ‘å¹¶ä¸éœ€è¦çŸ¥é“è¿™ä¸ª `workerChan` å…·ä½“æ˜¯åœ¨å“ªå„¿çš„ï¼šæ˜¯æ›¾ç»ç”¨è¿‡ï¼ˆ`wp.ready`ï¼‰è¿˜æ˜¯èˆ¹æ–°ç‰ˆæœ¬ï¼ˆ`n < 0`ï¼‰ã€‚æ‰€ä»¥è¿™é‡Œä¼šæœ‰ä¸ªåˆ¤æ–­ï¼Œå¦‚æœ `ready` å°±ç»ªé˜Ÿåˆ—é‡Œå·²ç»æœ‰äº†ï¼Œå°±è®©æš–ç©èƒçš„å…ˆè·‘ï¼Œç„¶åå†å»è®¿é—®å†…å­˜æ± ï¼Œçœ‹çœ‹å†…å­˜æ± é‡Œæœ‰æ²¡æœ‰æˆ‘ä»¬éœ€è¦çš„ã€‚å½“ç„¶ï¼Œä¸ `VictoriaMetrics` ä¸­ç•¥å¸¦å·®å¼‚çš„æ˜¯ï¼Œç”±äºè®¾ç½®äº† `sync.Pool.New` ï¼ŒGoä¼šè‡ªåŠ¨è¿”å›é `nil` çš„ `any` ï¼Œä¹Ÿè®¸æ˜¯ä¸ªè¿›æ­¥ï¼ˆå¤§æ¦‚ï¼Ÿï¼‰ã€‚

å¦‚æœ `workerChan` è¾¾åˆ°äº†ä¸Šé™å‘¢ï¼Œä¹Ÿå°±æ˜¯ `MaxWorkersCount` ï¼Œé‚£ä¹ˆå°†è¿”å› `nil` è¡¨ç¤ºæ‰¾ä¸åˆ°ã€‚



#### workerPool.release(ch *workerChan)

```go
func (wp *workerPool) release(ch *workerChan) bool {
	ch.lastUseTime = time.Now()
	wp.lock.Lock()
	if wp.mustStop {
		wp.lock.Unlock()
		return false
	}
	wp.ready = append(wp.ready, ch)
	wp.lock.Unlock()
	return true
}
```

è¿™é‡Œé¦–å…ˆæ›´æ–°äº†ä¸€ä¸‹ä½¿ç”¨æ—¶é—´ï¼Œç„¶åæ‰”ç»™äº† `ready` é˜Ÿåˆ—åšå¤ç”¨ï¼Œå½“ç„¶ï¼Œå¦‚æœ `wp` å·²ç»åœ¨æ­¤ä¹‹å‰å°±è¢«é€šçŸ¥å…³é—­ï¼Œé‚£è¿™ä¸ª `workerChan` å°±ç›´æ¥è¢«æ— è§†äº¤ç»™GCå¤„ç†äº†ã€‚

è¿™ä¸€éƒ¨åˆ†ä¹Ÿå°±æ˜¯ [ants](https://github.com/panjf2000/ants) å€Ÿé‰´çš„éƒ¨åˆ†ï¼Œå¾ˆç®€å•ä½†æ˜¯å¾ˆå·§å¦™ï¼Œå’Œæ•°æ®åº“çš„è¿æ¥æ± æœ‰ç›¸ä¼¼çš„ç¾æ„Ÿã€‚



### workerå·¥ä½œ

```go
func (wp *workerPool) workerFunc(ch *workerChan) {
	var c net.Conn

	var err error
	for c = range ch.ch {
		if c == nil {
			break
		}

		if err = wp.WorkerFunc(c); err != nil && err != errHijacked {
			errStr := err.Error()
			if wp.LogAllErrors || !(strings.Contains(errStr, "broken pipe") ||
				strings.Contains(errStr, "reset by peer") ||
				strings.Contains(errStr, "request headers: small read buffer") ||
				strings.Contains(errStr, "unexpected EOF") ||
				strings.Contains(errStr, "i/o timeout") ||
				errors.Is(err, ErrBadTrailer)) {
				wp.Logger.Printf("error when serving connection %q<->%q: %v", c.LocalAddr(), c.RemoteAddr(), err)
			}
		}
		if err == errHijacked {
			wp.connState(c, StateHijacked)
		} else {
			_ = c.Close()
			wp.connState(c, StateClosed)
		}
		c = nil

		if !wp.release(ch) {
			break
		}
	}

	wp.lock.Lock()
	wp.workersCount--
	wp.lock.Unlock()
}
```

è°ƒç”¨å…ˆå‰ä¼ å…¥çš„ `ServeHandler` ç±»å‹çš„ `WorkerFunc` ï¼Œç”¨äºå¤„ç†ä¼ å…¥çš„ `net.Conn` ï¼Œå‰©ä¸‹çš„å°±æ˜¯ä¸€äº›è¾¹ç•Œæ£€æŸ¥å’Œé”™è¯¯å¤„ç†ã€‚



### å‰©ä¸‹çš„

```go
func (s *Server) Serve(ln net.Listener) error {
	...
	// Count our waiting to accept a connection as an open connection.
	// This way we can't get into any weird state where just after accepting
	// a connection Shutdown is called which reads open as 0 because it isn't
	// incremented yet.
	atomic.AddInt32(&s.open, 1)
	defer atomic.AddInt32(&s.open, -1)

	for {
		if c, err = acceptConn(s, ln, &lastPerIPErrorTime); err != nil {
			wp.Stop()
			if err == io.EOF {
				return nil
			}
			return err
		}
		s.setState(c, StateNew)
		atomic.AddInt32(&s.open, 1)
		if !wp.Serve(c) {
			atomic.AddInt32(&s.open, -1)
			s.writeFastError(c, StatusServiceUnavailable,
				"The connection cannot be served because Server.Concurrency limit exceeded")
			c.Close()
			s.setState(c, StateClosed)
			if time.Since(lastOverflowErrorTime) > time.Minute {
				s.logger().Printf("The incoming connection cannot be served, because %d concurrent connections are served. "+
					"Try increasing Server.Concurrency", maxWorkersCount)
				lastOverflowErrorTime = time.Now()
			}

			// The current server reached concurrency limit,
			// so give other concurrently running servers a chance
			// accepting incoming connections on the same address.
			//
			// There is a hope other servers didn't reach their
			// concurrency limits yet :)
			//
			// See also: https://github.com/valyala/fasthttp/pull/485#discussion_r239994990
			if s.SleepWhenConcurrencyLimitsExceeded > 0 {
				time.Sleep(s.SleepWhenConcurrencyLimitsExceeded)
			}
		}
		c = nil
	}
}
```

```go
func acceptConn(s *Server, ln net.Listener, lastPerIPErrorTime *time.Time) (net.Conn, error) {
	for {
		c, err := ln.Accept()
		if err != nil {
			if c != nil {
				panic("BUG: net.Listener returned non-nil conn and non-nil error")
			}
			if netErr, ok := err.(net.Error); ok && netErr.Timeout() {
				s.logger().Printf("Timeout error when accepting new connections: %v", netErr)
				time.Sleep(time.Second)
				continue
			}
			if err != io.EOF && !strings.Contains(err.Error(), "use of closed network connection") {
				s.logger().Printf("Permanent error when accepting new connections: %v", err)
				return nil, err
			}
			return nil, io.EOF
		}
		if c == nil {
			panic("BUG: net.Listener returned (nil, nil)")
		}

		if tc, ok := c.(*net.TCPConn); ok && s.TCPKeepalive {
			if err := tc.SetKeepAlive(s.TCPKeepalive); err != nil {
				tc.Close() //nolint:errcheck
				return nil, err
			}
			if s.TCPKeepalivePeriod > 0 {
				if err := tc.SetKeepAlivePeriod(s.TCPKeepalivePeriod); err != nil {
					tc.Close() //nolint:errcheck
					return nil, err
				}
			}
		}

		if s.MaxConnsPerIP > 0 {
			pic := wrapPerIPConn(s, c)
			if pic == nil {
				if time.Since(*lastPerIPErrorTime) > time.Minute {
					s.logger().Printf("The number of connections from %s exceeds MaxConnsPerIP=%d",
						getConnIP4(c), s.MaxConnsPerIP)
					*lastPerIPErrorTime = time.Now()
				}
				continue
			}
			c = pic
		}
		return c, nil
	}
}
```

å‰©ä¸‹çš„ä¸€äº›ä¹Ÿæ²¡å…¶ä»–çš„äº†ï¼Œ**å ‚å ‚ä¼‘åˆŠ**ï¼